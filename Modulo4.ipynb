{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Módulo_4 (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlcibMKA_a-j"
      },
      "source": [
        "# Módulo 4 - Aprendizado supervisionado\n",
        "\n",
        "Neste notebook, implementaremos algoritmos de aprendizado supervisionado. Na primeira parte, veremos a implementação de árvores de decisão. Na segunda parte, veremos a random forests. Para isto, utilizaremos a biblioteca [scikit-learn](http://scikit-learn.org) do Python. Em ambos os casos, o objetivo é entender como estes algoritmos funcionam. Ao final, você deverá realizar os exercícios propostos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqWhkCoq_jyp"
      },
      "source": [
        "## Parte 1 - Árvores de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAFF0wpoqcKt"
      },
      "source": [
        "Primeiramente, precisamos importar algumas bibliotecas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnzYoE-K_qfP"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO \n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from IPython.display import Image \n",
        "from pydot import graph_from_dot_data\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffMwKq4kqwFR"
      },
      "source": [
        "Feito isto, agora iremos importar um dataset clássico da literatura, o [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris). Felizmente, este dataset já está incluído na biblioteca scikit-learn. Desta forma, basta executar o comando abaixo para importá-lo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_VPUwgcrWJU"
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be1H39tprWgB"
      },
      "source": [
        "O dataset acima possui diversas instâncias de exemplo. Nosso objetivo é utilizar aprendizado supervisionado para aprender a distinguir espécies de iris com base na largura e comprimento de suas sépalas e pétalas. Para isto, precisamos separar as colunas representando as features de entrada (variável `X` abaixo) das classes de saída (variável `y` abaixo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WS6aJZTibsW"
      },
      "source": [
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Categorical.from_codes(iris.target, iris.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgHTfzXCr9_5"
      },
      "source": [
        "Para entender melhor os dados de entrada, podemos listar os primeiros 10 registros como segue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJotRo01ibx-"
      },
      "source": [
        "X.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlMVz1JvsFAc"
      },
      "source": [
        "Da mesma forma, podemos verificar os dados de saída como segue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAW5JQqKT5I-"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71niLZqrsK7-"
      },
      "source": [
        "Com base na saída acima, note que temos 150 amostras de iris. Podemos ver também que as amostras de iris pertencem às espécies iris setosa, iris versicolor e iris virginica.\n",
        "\n",
        "Agora, precisamos converter os dados de saída para um formato [categórico](https://pt.wikipedia.org/wiki/Variável_categórica). Isto vai facilitar o processo de aprendizagem. Para isto, podemos executar o comando abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdvl-OYBib0r"
      },
      "source": [
        "y = pd.get_dummies(y)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_zAIcc3saYN"
      },
      "source": [
        "Com os comandos acima, agora temos um conjunto de exemplos de entrada (`X`) e saída (`y`). No entanto, lembre-se que, para poder validar os modelos aprendidos, é preciso não apenas treiná-los, mas também testá-los. Para isto, podemos dividir aleatoriamente o conjunto de dados em conjunto de treino e de teste como segue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y4LdwOoib3j"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nixhvcIys12K"
      },
      "source": [
        "Até aqui, nosso objetivo foi processar os dados. Agora podemos nos preocupar com os algoritmos em si.\n",
        "\n",
        "O código abaixo cria uma instância do algoritmo [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) para a tarefa de classificação. Em sua chamada padrão, o algoritmo utiliza o índice Gini para escolher as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-fvHdActHVu"
      },
      "source": [
        "dt = DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUAYaH_TtGw9"
      },
      "source": [
        "Criado o algoritmo, agora podemos finalmente treinar o modelo. Para isto, basta chamar a função `fit`, que recebe um conjunto de dados de treino (separados em entradas e saídas) e encontra a melhor árvore de decisão para representar estes dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyhWG49zi3LY"
      },
      "source": [
        "dt.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEUQVn6hulR_"
      },
      "source": [
        "Após treinar o algoritmo, podemos analisar os resultados. Primeiramente, vamos visualizar a árvore resultante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBsAn1QQi3fp"
      },
      "source": [
        "dot_data = StringIO()\n",
        "export_graphviz(dt, out_file=dot_data, feature_names=iris.feature_names)\n",
        "(graph, ) = graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im0KY2QtuyW7"
      },
      "source": [
        "Para avaliar nosso algoritmo, podemos verificar o quão bem ele se sai na classificação de dados novos. Para isto, podemos utilizar os dados de teste. \n",
        "\n",
        "Em particular, a função `predict` recebe um conjunto de dados de entrada (`X_test`) e retorna a classificação obtida através do algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bim_SZAHi3iz"
      },
      "source": [
        "y_pred = dt.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fozeaiHQvKKb"
      },
      "source": [
        "Para medir o desempenho do nosso método, podemos calcular algumas métricas como acurácia, precisão e recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5bBht9qwi6S"
      },
      "source": [
        "a = accuracy_score(y_test, y_pred)\n",
        "p = precision_score(y_test, y_pred, average='micro')\n",
        "r = recall_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print('Accuracy:\\t%f' % a)\n",
        "print('Precision:\\t%f' % p)\n",
        "print('Recall: \\t%f' % r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoVQWhEiwjBy"
      },
      "source": [
        "Os resultados acima mostram que o algoritmo obteve um bom desempenho. De fato, ao gerar a matriz de confusão abaixo, podemos observar que os apenas uma instância foi classificada incorretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55D50oz7i3mh"
      },
      "source": [
        "species = np.array(y_test).argmax(axis=1)\n",
        "predictions = np.array(y_pred).argmax(axis=1)\n",
        "confusion_matrix(species, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GARK4PZu_tve"
      },
      "source": [
        "### Exercício 1\n",
        "\n",
        "Crie uma árvore de decisão para resolver um dos outros datasets de classificação disponíveis no scikit-learn. A lista de datasets pode ser encontrada [aqui](https://scikit-learn.org/stable/datasets/real_world.html). A tarefa consiste em importar os dados, treinar o algoritmo e avaliar os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCvkVPfHAGks"
      },
      "source": [
        "# sua resposta aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ6T53LM_j1t"
      },
      "source": [
        "## Parte 2 - Random forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB4GSNaF31r1"
      },
      "source": [
        "Nesta segunda parte do notebook, veremos como utilizar random forests.\n",
        "\n",
        "Primeiramente, precisamos importar os dados e tratá-los novamente. Utilizaremos novamente o dataset de plantas iris. O código é basicamente o mesmo, então basta executar o trecho abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff4T3u5O_fx6",
        "cellView": "form"
      },
      "source": [
        "#@title Código-base de importação do dataset (basta executar)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO \n",
        "from IPython.display import Image \n",
        "from pydot import graph_from_dot_data\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
        "\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOLz_Ga_4Zxd"
      },
      "source": [
        "Agora podemos criar uma instância de `RandomForestClassifier` ([documentação](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). Esta instância cria um algoritmo random forest para a tarefa de classificação. No exemplo abaixo, utilizamos a entropia para escolher as features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbFlovrljp74"
      },
      "source": [
        "rf = RandomForestClassifier(criterion='entropy', oob_score=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGSzwg3B5P_u"
      },
      "source": [
        "Criado o algoritmo, agora podemos treiná-lo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zVwAE0JjqBf"
      },
      "source": [
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKPdfn4f5WWn"
      },
      "source": [
        "Agora, podemos visualizar uma das árvores de decisão resultantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqf9dT31jqIq"
      },
      "source": [
        "dt = rf.estimators_[0]\n",
        "dot_data = StringIO()\n",
        "export_graphviz(dt, out_file=dot_data, feature_names=iris.feature_names)\n",
        "(graph, ) = graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8DdRJd05v7E"
      },
      "source": [
        "Para analisar o desempenho do algoritmo, podemos calcular algumas métricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZKSrcMn531R"
      },
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "a = accuracy_score(y_test, y_pred)\n",
        "p = precision_score(y_test, y_pred, average='micro')\n",
        "r = recall_score(y_test, y_pred, average='micro')\n",
        "\n",
        "print('Accuracy:\\t%f' % a)\n",
        "print('Precision:\\t%f' % p)\n",
        "print('Recall: \\t%f' % r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-5bR8Hn58oQ"
      },
      "source": [
        "Além do mais, podemos analisar a matriz de confusão. Novamente, note que o resultado ficou bastante bom e que apenas uma instância foi classificada incorretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJD4T2l6jqSV"
      },
      "source": [
        "classes = np.array(y_test).argmax(axis=1)\n",
        "predictions = np.array(y_pred).argmax(axis=1)\n",
        "confusion_matrix(classes, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHRr4bOL_-Nz"
      },
      "source": [
        "### Exercício 2\n",
        "\n",
        "Crie uma random forest para resolver um dos outros datasets de classificação disponíveis no scikit-learn. A lista de datasets pode ser encontrada [aqui](https://scikit-learn.org/stable/datasets/real_world.html). Utilize um dataset diferente do utilizado no exercício 1. A tarefa consiste em importar os dados, treinar o algoritmo e avaliar os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IJrFAeUAKdJ"
      },
      "source": [
        "# sua resposta aqui"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}